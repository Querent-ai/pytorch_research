{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMyFK3IfIBYNAf7ilblAVKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Querent-ai/pytorch_research/blob/main/Facies_Across_Wells_1DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[Facies Prediction with Class Weighting & Visualization](https://)**"
      ],
      "metadata": {
        "id": "kKGCvY9uek9p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v05z_ETQeh3y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"mcmurray_facies_v1.csv\")\n",
        "df = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "\n",
        "features = ['GR', 'RHOB', 'NPHI', 'PHI', 'VSH']\n",
        "df = df.dropna(subset=features + ['lithName', 'UWI'])\n",
        "\n",
        "# Optional: remove very rare or unclear facies\n",
        "df = df[df['lithName'] != 'CementedSand']\n",
        "df = df[df['lithName'] != 'Undefined']  # or whatever the rare class is\n",
        "df['lithName'].value_counts()\n"
      ],
      "metadata": {
        "id": "GIP0GCQce1qE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f79aa882-ec34-4adf-ef1b-122dc50ee072"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lithName\n",
              "Sand          4824\n",
              "Shale         3593\n",
              "ShalySand     3454\n",
              "Coal          3146\n",
              "SandyShale     240\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lithName</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sand</th>\n",
              "      <td>4824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shale</th>\n",
              "      <td>3593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ShalySand</th>\n",
              "      <td>3454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coal</th>\n",
              "      <td>3146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SandyShale</th>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['FaciesEncoded'] = le.fit_transform(df['lithName'])\n",
        "classes = le.classes_\n",
        "from collections import Counter\n",
        "print(Counter(df['FaciesEncoded']))\n"
      ],
      "metadata": {
        "id": "XS-YUVhynEgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb136374-bc5c-4e9c-8b4a-e977ca1a9fbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1: 4824, 3: 3593, 4: 3454, 0: 3146, 2: 240})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 10\n",
        "X_windows, y_windows, uwi_windows = [], [], []\n",
        "\n",
        "for i in range(len(df) - window_size):\n",
        "    window = df.iloc[i:i+window_size]\n",
        "    if len(window['FaciesEncoded'].unique()) == 1:  # target consistency\n",
        "        X_windows.append(window[features].values)\n",
        "        y_windows.append(window['FaciesEncoded'].iloc[-1])\n",
        "        uwi_windows.append(window['UWI'].iloc[-1])\n",
        "\n",
        "X_windows = np.stack(X_windows)\n",
        "y_windows = np.array(y_windows)\n",
        "uwi_windows = np.array(uwi_windows)\n"
      ],
      "metadata": {
        "id": "KLKCWjbvoJJh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaciesCNN1D(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1)\n",
        "        )\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # shape: (batch, features, window)\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "EiuimQQBoMqp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FaciesWindowDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "Q4Uf6FhIoPdp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(sgkf.split(X_windows, y_windows, groups=uwi_windows)):\n",
        "    print(f\"\\nFold {fold+1}\")\n",
        "\n",
        "    X_train, X_test = X_windows[train_idx], X_windows[test_idx]\n",
        "    y_train, y_test = y_windows[train_idx], y_windows[test_idx]\n",
        "\n",
        "    train_loader = DataLoader(FaciesWindowDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(FaciesWindowDataset(X_test, y_test), batch_size=64)\n",
        "\n",
        "    model = FaciesCNN1D(input_channels=len(features), num_classes=len(classes))\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):  # Increase if needed\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in test_loader:\n",
        "            out = model(xb)\n",
        "            preds = torch.argmax(out, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(yb.cpu().numpy())\n",
        "\n",
        "    # Filter class labels present in this fold\n",
        "    labels_present = sorted(unique_labels(all_labels, all_preds))\n",
        "    label_names_present = [classes[i] for i in labels_present]\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        all_labels,\n",
        "        all_preds,\n",
        "        labels=labels_present,\n",
        "        target_names=label_names_present,\n",
        "        zero_division=0\n",
        "    ))\n"
      ],
      "metadata": {
        "id": "FP6ijhxOohVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52360557-d174-4e59-da13-33eb8c011de4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "Epoch 1, Loss: 0.6339\n",
            "Epoch 2, Loss: 0.1432\n",
            "Epoch 3, Loss: 0.0730\n",
            "Epoch 4, Loss: 0.0451\n",
            "Epoch 5, Loss: 0.0265\n",
            "Epoch 6, Loss: 0.0205\n",
            "Epoch 7, Loss: 0.0158\n",
            "Epoch 8, Loss: 0.0130\n",
            "Epoch 9, Loss: 0.0074\n",
            "Epoch 10, Loss: 0.0083\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Coal       1.00      0.99      1.00       284\n",
            "        Sand       1.00      1.00      1.00       607\n",
            "  SandyShale       0.00      0.00      0.00         0\n",
            "       Shale       1.00      1.00      1.00       103\n",
            "   ShalySand       1.00      0.99      0.99        91\n",
            "\n",
            "    accuracy                           1.00      1085\n",
            "   macro avg       0.80      0.80      0.80      1085\n",
            "weighted avg       1.00      1.00      1.00      1085\n",
            "\n",
            "\n",
            "Fold 2\n",
            "Epoch 1, Loss: 0.7064\n",
            "Epoch 2, Loss: 0.1622\n",
            "Epoch 3, Loss: 0.0705\n",
            "Epoch 4, Loss: 0.0412\n",
            "Epoch 5, Loss: 0.0270\n",
            "Epoch 6, Loss: 0.0234\n",
            "Epoch 7, Loss: 0.0251\n",
            "Epoch 8, Loss: 0.0195\n",
            "Epoch 9, Loss: 0.0115\n",
            "Epoch 10, Loss: 0.0096\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Coal       0.98      1.00      0.99       302\n",
            "        Sand       0.99      1.00      1.00       803\n",
            "  SandyShale       1.00      0.33      0.50         9\n",
            "       Shale       1.00      0.93      0.97        91\n",
            "   ShalySand       1.00      1.00      1.00        66\n",
            "\n",
            "    accuracy                           0.99      1271\n",
            "   macro avg       0.99      0.85      0.89      1271\n",
            "weighted avg       0.99      0.99      0.99      1271\n",
            "\n",
            "\n",
            "Fold 3\n",
            "Epoch 1, Loss: 0.7052\n",
            "Epoch 2, Loss: 0.1802\n",
            "Epoch 3, Loss: 0.0829\n",
            "Epoch 4, Loss: 0.0558\n",
            "Epoch 5, Loss: 0.0425\n",
            "Epoch 6, Loss: 0.0266\n",
            "Epoch 7, Loss: 0.0259\n",
            "Epoch 8, Loss: 0.0215\n",
            "Epoch 9, Loss: 0.0185\n",
            "Epoch 10, Loss: 0.0161\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Coal       0.90      1.00      0.95       174\n",
            "        Sand       1.00      0.97      0.99       960\n",
            "  SandyShale       0.69      1.00      0.82         9\n",
            "       Shale       1.00      1.00      1.00        36\n",
            "   ShalySand       0.96      1.00      0.98        79\n",
            "\n",
            "    accuracy                           0.98      1258\n",
            "   macro avg       0.91      0.99      0.95      1258\n",
            "weighted avg       0.98      0.98      0.98      1258\n",
            "\n"
          ]
        }
      ]
    }
  ]
}